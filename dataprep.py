# -*- coding: utf-8 -*-
"""Google Brain-Ventilator Pressure_DataPrep.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Bu6oUu_W5kqVPUBG4yWkDPnp0DQklCVc
"""

! gdown 1cWmgIyUueyNwjYLQV_ZRq4iKKTl6aj5y

! gdown 1xeoROH9QNZgEIOcvis8nWH6nqUQyLNqJ

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

import warnings
warnings.filterwarnings('ignore')

train=pd.read_csv('train.csv')
test=pd.read_csv('test.csv')

def reduce_mem_usage(df, verbose=True):
    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']
    start_mem = df.memory_usage(deep=True).sum() / 1024 ** 2 # just added 
    for col in df.columns:
        col_type = df[col].dtypes
        if col_type in numerics:
            c_min = df[col].min()
            c_max = df[col].max()
            if str(col_type)[:3] == 'int':
                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
                    df[col] = df[col].astype(np.int8)
                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                    df[col] = df[col].astype(np.int16)
                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                    df[col] = df[col].astype(np.int32)
                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:
                    df[col] = df[col].astype(np.int64)  
            else:
                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:
                    df[col] = df[col].astype(np.float16)
                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:
                    df[col] = df[col].astype(np.float32)
                else:
                    df[col] = df[col].astype(np.float64)    
    end_mem = df.memory_usage(deep=True).sum() / 1024 ** 2
    percent = 100 * (start_mem - end_mem) / start_mem
    print('Mem. usage decreased from {:5.2f} Mb to {:5.2f} Mb ({:.1f}% reduction)'.format(start_mem, end_mem, percent))
    return df

train.columns

for df in [train, test]:
  df.drop('id', axis=1, inplace=True)

"""Removing **Outliers**"""

#from scipy import stats

#z = np.abs(stats.zscore(train['pressure']))
#idx=np.where(z > 3)
#len(train.iloc[idx])

#train=train.drop(train.index[idx], axis=0)

"""**FE**"""

for df in [train, test]:
  df['shifted1_u_in']=df['u_in'].shift(1).where(df.breath_id.eq(df.breath_id.shift())).fillna(0)
  df['shifted2_u_in']=df['u_in'].shift(2).where(df.breath_id.eq(df.breath_id.shift())).fillna(0)
  df['shifted3_u_in']=df['u_in'].shift(3).where(df.breath_id.eq(df.breath_id.shift())).fillna(0)
  df['u_in_diff1']=df['u_in']-df['shifted1_u_in']
  df['u_in_diff2']=df['u_in']-df['shifted2_u_in']
  df['u_in_diff3']=df['u_in']-df['shifted3_u_in']
  df['rshifted1_u_in']=df['u_in'].shift(-1).where(df.breath_id.eq(df.breath_id.shift())).fillna(0)
  df['rshifted2_u_in']=df['u_in'].shift(-2).where(df.breath_id.eq(df.breath_id.shift())).fillna(0)
  df['rshifted3_u_in']=df['u_in'].shift(-3).where(df.breath_id.eq(df.breath_id.shift())).fillna(0)
  df['rshifted4_u_in']=df['u_in'].shift(-4).where(df.breath_id.eq(df.breath_id.shift())).fillna(0)
  df['u_in_max']=df.groupby('breath_id')['u_in'].transform('max')
  df['u_in_mean']=df.groupby('breath_id')['u_in'].transform('mean')
  df['u_in_diff_max']=df.groupby('breath_id')['u_in_diff1'].transform('max')
  df['u_in_diff_mean']=df.groupby('breath_id')['u_in_diff1'].transform('mean')

for df in [train, test]:
  df['area'] = df['time_step'] * df['u_in']
  df['area'] = df.groupby('breath_id')['area'].cumsum()
  df['time_step_cumsum'] = df.groupby(['breath_id'])['time_step'].cumsum()
  df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()
  df['exponent']=(- df['time_step'])/(df['R']*df['C'])
  df['factor']=np.exp(df['exponent'])
  df['vf']=(df['u_in_cumsum']*df['R'])/df['factor']
  df['vt']=0
  df.loc[df['time_step'] != 0, 'vt']=df['area']/(df['C']*(1 - df['factor']))
  df['v']=df['vf']+df['vt']

for df in [train, test]:
  df['R']=df['R'].astype('str')
  df['C']=df['C'].astype('str')
  df['R__C']=(df['R'].astype('str'))+'__'+(df['C'].astype('str'))

def encode_onehot(train,test,column_name):
  df=pd.concat([train,test])
  feature_df=pd.get_dummies(df[column_name], prefix=column_name)
  all = pd.concat([df.drop([column_name], axis=1),feature_df], axis=1)

  train=all.iloc[:len(train)].reset_index(drop=True)
  test=all.iloc[len(train):].drop('pressure', axis=1).reset_index(drop=True)
  return train, test

train, test=encode_onehot(train,test,'R')
train, test=encode_onehot(train,test,'C')
train, test=encode_onehot(train,test,'R__C')

train=reduce_mem_usage(train)
test=reduce_mem_usage(test)

for df in [train, test]:
  df.drop('breath_id', axis=1, inplace=True)

train.to_csv('Google_VP_train.csv', index=False)
test.to_csv('Google_VP_test.csv', index=False)

from google.colab import files

files.download('Google_VP_train.csv')
files.download('Google_VP_test.csv')